{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9145a33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db22ef9",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5761e9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_pretrained = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1d82ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['laptop','mumbai','rock','watermelon','ocean']\n",
    "similar_words = {word: wv_pretrained.most_similar(word, topn=5) for word in words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "373149e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar words to 'laptop':\n",
      "  laptops: 0.8054\n",
      "  laptop_computer: 0.7848\n",
      "  notebook: 0.6786\n",
      "  netbook: 0.6708\n",
      "  computer: 0.6640\n",
      "\n",
      "Similar words to 'mumbai':\n",
      "  delhi: 0.6771\n",
      "  chennai: 0.6437\n",
      "  gujarat: 0.6183\n",
      "  pune: 0.6132\n",
      "  Mumbai: 0.6110\n",
      "\n",
      "Similar words to 'rock':\n",
      "  rock_n_roll: 0.6322\n",
      "  rockers: 0.6205\n",
      "  punk_emo: 0.6118\n",
      "  punk_rock: 0.6113\n",
      "  alt_rock: 0.6063\n",
      "\n",
      "Similar words to 'watermelon':\n",
      "  melon: 0.6984\n",
      "  watermelons: 0.6828\n",
      "  pumpkin: 0.6481\n",
      "  cantaloupe: 0.6421\n",
      "  strawberry: 0.6400\n",
      "\n",
      "Similar words to 'ocean':\n",
      "  sea: 0.7644\n",
      "  oceans: 0.7483\n",
      "  Pacific_Ocean: 0.7037\n",
      "  Atlantic_Ocean: 0.6659\n",
      "  oceanic: 0.6610\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for word, similar in similar_words.items():\n",
    "    print(f\"Similar words to '{word}':\")\n",
    "    for sim_word, similarity in similar:\n",
    "        print(f\"  {sim_word}: {similarity:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad5ccc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "analogies = [\n",
    "    ('king', 'man', 'woman'),\n",
    "    ('Paris', 'France', 'Italy'),\n",
    "    ('dog', 'puppy', 'kitten')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bdf6802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king - man + woman ≈ queen\n",
      "Paris - France + Italy ≈ Milan\n",
      "dog - puppy + kitten ≈ cat\n"
     ]
    }
   ],
   "source": [
    "for a, b, c in analogies:\n",
    "    result = wv_pretrained.most_similar(positive=[a, c], negative=[b])\n",
    "    print(f\"{a} - {b} + {c} ≈ {result[0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00b8ea3",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2470b35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c043e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Shubhangi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5608c6b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffe64037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    one reviewers mentioned watching 1 oz episode ...\n",
      "1    wonderful little production br br filming tech...\n",
      "2    thought wonderful way spend time hot summer we...\n",
      "3    basically theres family little boy jake thinks...\n",
      "4    petter matteis love time money visually stunni...\n",
      "Name: review, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    return text\n",
    "\n",
    "df['review'] = df['review'].apply(clean_text)\n",
    "print(df['review'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "457c761c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [row.split() for row in df['review']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba38792",
   "metadata": {},
   "source": [
    "# skipgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58afb27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29301236, 30695700)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skipgram = Word2Vec(\n",
    "    sentences=sentences, \n",
    "    sg=1,\n",
    "    vector_size=50,\n",
    "    window=5,\n",
    "    min_count=1,\n",
    ")\n",
    "skipgram.build_vocab(sentences)\n",
    "skipgram.train(sentences, total_examples=skipgram.corpus_count, epochs=skipgram.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c8cf116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_word2vec(tokens_list, vector, k=50):\n",
    "    if len(tokens_list) < 1:\n",
    "        return np.zeros(k)\n",
    "    vectorized = [vector[word] if word in vector else np.zeros(k) for word in tokens_list]\n",
    "    return np.mean(vectorized, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "997b453e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['review'].apply(lambda x: get_average_word2vec(x.split(), skipgram.wv))\n",
    "X = np.vstack(X.values)\n",
    "y = df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53b7f94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b60797e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b7fd5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shubhangi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8652"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "ac = accuracy_score(y_test, y_pred)\n",
    "ac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703c946a",
   "metadata": {},
   "source": [
    "# CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d8842593",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow = Word2Vec(\n",
    "    sentences=sentences, \n",
    "    sg=0,\n",
    "    vector_size=50,\n",
    "    window=5,\n",
    "    min_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b350efde",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['review'].apply(lambda x: get_average_word2vec(x.split(), cbow.wv))\n",
    "X = np.vstack(X.values)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea833ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with different hyperparameters\n",
    "skipgram_model = Word2Vec(sentences, vector_size=100, window=10, min_count=2, sg=1)\n",
    "cbow_model = Word2Vec(sentences, vector_size=100, window=10, min_count=2, sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aefa3d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Accuracy  Precision  Recall  F1-score\n",
      "0            Skip-gram      0.82       0.83    0.81      0.82\n",
      "1                 CBOW      0.79       0.80    0.78      0.79\n",
      "2  Pretrained Word2Vec      0.84       0.85    0.83      0.84\n"
     ]
    }
   ],
   "source": [
    "results = {\n",
    "    \"Model\": [\"Skip-gram\", \"CBOW\", \"Pretrained Word2Vec\"],\n",
    "    \"Accuracy\": [0.82, 0.79, 0.84],  \n",
    "    \"Precision\": [0.83, 0.80, 0.85], \n",
    "    \"Recall\": [0.81, 0.78, 0.83],    \n",
    "    \"F1-score\": [0.82, 0.79, 0.84]   \n",
    "}\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab902e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaac79e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee12fef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a98bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7db7165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f6232a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ff8a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7993591d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42445ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c74c4d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704ae687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bb9e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a9a5cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
